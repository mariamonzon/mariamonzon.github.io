<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.6.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Maria Monzon" />

  
  
  
    
  
  <meta name="description" content="Small ilustrative example of Reinforcement Learning algorithm for optimal-storing objects in a warehouse." />

  
  <link rel="alternate" hreflang="en-us" href="https://mariamonzon.com/project/reinforcement-learning-warehouse/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.3495fc6150afdd177f1d04fbba9f5e2c.css" />

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



  


  


  




  
  
  

  
  

  
  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  
  <link rel="icon" type="image/png" href="/media/icon_huaad826f52d8c51d03abf0418cbb027d5_448596_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_huaad826f52d8c51d03abf0418cbb027d5_448596_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://mariamonzon.com/project/reinforcement-learning-warehouse/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
    <meta property="twitter:site" content="@wowchemy" />
    <meta property="twitter:creator" content="@wowchemy" />
  
  <meta property="og:site_name" content="Maria Monzon" />
  <meta property="og:url" content="https://mariamonzon.com/project/reinforcement-learning-warehouse/" />
  <meta property="og:title" content="Warehouse storing route optimization with Reinforcement Learning | Maria Monzon" />
  <meta property="og:description" content="Small ilustrative example of Reinforcement Learning algorithm for optimal-storing objects in a warehouse." /><meta property="og:image" content="https://mariamonzon.com/project/reinforcement-learning-warehouse/featured.png" />
    <meta property="twitter:image" content="https://mariamonzon.com/project/reinforcement-learning-warehouse/featured.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2020-12-15T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2020-12-15T00:00:00&#43;00:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://mariamonzon.com/project/reinforcement-learning-warehouse/"
  },
  "headline": "Warehouse storing route optimization with Reinforcement Learning",
  
  "image": [
    "https://mariamonzon.com/project/reinforcement-learning-warehouse/featured.png"
  ],
  
  "datePublished": "2020-12-15T00:00:00Z",
  "dateModified": "2020-12-15T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Maria Monzon"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Maria Monzon",
    "logo": {
      "@type": "ImageObject",
      "url": "https://mariamonzon.com/media/icon_huaad826f52d8c51d03abf0418cbb027d5_448596_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Small ilustrative example of Reinforcement Learning algorithm for optimal-storing objects in a warehouse."
}
</script>

  

  

  
  
  
  
  
    <script src="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.js" integrity="sha512-yXXqOFjdjHNH1GND+1EO0jbvvebABpzGKD66djnUfiKlYME5HGMUJHoCaeE4D5PTG2YsSJf6dwqyUUvQvS0vaA==" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.css" integrity="sha512-LQ97camar/lOliT/MqjcQs5kWgy6Qz/cCRzzRzUCfv0fotsCTC9ZHXaPQmJV8Xu/PVALfJZ7BDezl5lW3/qBxg==" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#1565c0",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#1565c0"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://www.cookiesandyou.com"
      }
    })});
  </script>



  <title>Warehouse storing route optimization with Reinforcement Learning | Maria Monzon</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="576f0271e91063ffb865aa572837b605" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.613040fe4f2c0f007b4dcb64404201cb.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Maria Monzon</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Maria Monzon</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/cv/"><span>Experience</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/portfolio/"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/publication/"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article article-project">

  





















  
  


<div class="article-container pt-3">
  <h1>Warehouse storing route optimization with Reinforcement Learning</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Dec 15, 2020
  </span>
  

  

  

  
  
  
  

  
  

</div>

  




<div class="btn-links mb-3">
  
  








  






  
  
    
  
<a class="btn btn-outline-primary btn-page-header" href="https://github.com/mariamonzon/Software-applications-with-AI/blob/main/RLWarehouseStorage" target="_blank" rel="noopener">
  Code
</a>














</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 320px;">
  <div style="position: relative">
    <img src="/project/reinforcement-learning-warehouse/featured_hu90ec0f3182455b2b963be49b3161d112_1732954_720x2500_fit_q75_h2_lanczos_3.webp" width="720" height="320" alt="" class="featured-image">
    <span class="article-header-caption">Optimization of the robots route for pick-up and storage of items in a warehouse</span>
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <p>The problem represents a storage decision process where outcome is under the control of a robot, i.e, a decision maker
agent, but also are partly random. Therefore, the problem can be well modeled as a discrete-time Markov Decision
Processes. The approach follow was:</p>
<ul>
<li>Implement a reinforcement-learning based algorithm</li>
<li>The robot is the agent and decides where to place the next part</li>
<li>Use the markov decision process toolbox for your solution</li>
<li>Choose the best performing MDP</li>
</ul>
<h2 id="defitinions">Defitinions</h2>
<p>The basic concepts to understand the promblem are shortly introduced based on <em>Artificial Intelligence: A Modern Approach</em> book:</p>
<ul>
<li>
<p><strong>Reinforcement learning</strong>: Type of dynamic programming that trains algorithms using
a system of reward and punishment. The agent learns without intervention from a human by maximizing its reward
and minimizing its penalty and updates itself continuously. The algorithm it automatically finds patterns
and relationships inside of that dataset. It requires realtime data.</p>
</li>
<li>
<p><strong>Agent</strong>: A is the set of all possible moves the agent can make. An action is almost self-explanatory, but it should be noted that agents choose among a list of possible actions.</p>
</li>
<li>
<p><strong>Environment</strong>: The world through which the agent moves. The environment takes the agent&rsquo;s current state and action as input, and returns as output the agent&rsquo;s reward and its next state.</p>
</li>
<li>
<p><strong>State</strong>: The parameter values that describe the current cofiguration of the environment, which the agent uses to choose an action. A state is a concrete and immediate situation in which the agent finds itself; i.e. a specific place and moment.</p>
</li>
<li>
<p><strong>Reward</strong>: Feedback by which we effectively evaluate the agent&rsquo;s action.
From any given state, an agent sends output in the form of actions to the environment, and the environment
returns the agent&rsquo;s new state (which resulted from actingon the previous state) as well as rewards, if any.
Rewards
can be immediate or delayed.</p>
</li>
<li>
<p><strong>Markov decision process</strong>: Markov decision processes (MDPS) is a model decision making in stochastic, sequential environments. The essence of the model is that a decision maker, or agent, inhabits an environment, which changes state randomly in response to action choices made by the agent. 
















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/images/reinforcement-learning-warehouse/agent-environment.png" alt="agent" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
</li>
</ul>
<h2 id="example-introduction">Example Introduction</h2>
<p>A tiny warehouse with (2x2) storage capacity locations is simulated. The picking robot (agent) interacts with the
warehouse (environment) by store-restoring items in each warehouse cell or shelve. The dataset contains store and
restore action for red, blue and white colored items although an empty field is also possible.</p>
<p>When the agent is placed on a field position (ğ‘¥ğ‘‘, ğ‘¦ğ‘‘), it can either store or restore each of the color items.
There exists a total of six possible actions to change its environment. The robot can move in the (2x2) grid
environment and start moving at initial grid position (1,1) . The robot is constrained to always to move only
to one adjacent fields (not in diagonal).</p>
<p>The distance the robot needs to move is derived based on current (ğ‘¥ğ‘ , ğ‘¦ğ‘ ) and goal position (ğ‘¥ğ‘‘ , ğ‘¦ğ‘‘). The
distance is calculated as the sum of the absolute differences of the layout position

$$ ğ‘‘ = |ğ‘¥_ğ‘‘ âˆ’ ğ‘¥_ğ‘ | + |ğ‘¦_ğ‘‘ âˆ’ ğ‘¦_ğ‘‘|$$ 
</p>
<p>Therefore, the distance to the position can be assigned to the cost of the action or negative reward. The ideal
goal of the reinforcement learning approach would be to optimize the route picking storage strategy by
minimizing the distance with rewards the store/restore motion actions.</p>
<h2 id="methods">Methods</h2>
<p>The Markov Discrete Process (MDP) algorithm was implemented for modelling the problem. A MDP is
described by state transition probabilities. A general Reinforcement Learning and thus also MDP algorithm
is defined with a set of variables:</p>
<ul>
<li>
<p>Actions (A): refers to the operations an agent can perform which direct modify the environment. In our
problem this are related to the effect on the warehouse grid cells, directly proportional to the warehouse size
(ğ‘‹, ğ‘Œ). $ A = \{ ğ´_{(1,1)}, ğ´_{(1,2)}, ğ´_{(2,1)}, â€¦ , ğ´_{(X,Y)}\}$  where  $ |ğ´| = |ğ‘‹ \cdot ğ‘Œ|$ .</p>
</li>
<li>
<p>States (S): represent all the possible configuration of environment, i.e, how the items are storage in the warehouse grid. In the addressed problem, the total states can be computed  $ |S| = \{ğ‘–ğ‘¡ğ‘’ğ‘šğ‘ _{ğ‘”ğ‘Ÿğ‘–ğ‘‘}*move_{action}  \}$  where the items on the grid is calculated as the exponential relation of colored items number to grid size, and the move actions represent all the possible robot movements {store: blue/red/white, restore: blue/red/white }.</p>
</li>
<li>
<p>Transition probability matrix (TMP) in Markov processes stores the probability to transition from the current state to a next possible state after the agent has performed given action in a single time unit. The dimension if this matrix is determined by (|ğ´|,|ğ‘†|,|ğ‘†|).</p>
</li>
<li>
<p>Reward matrix (R), is composed by the defined reward or symbolic benefit received performing and action ğ´(ğ‘¥,ğ‘¦) for a given state. The shape of this matrix (|ğ‘†|,|ğ´|).</p>
</li>
</ul>
<h3 id="transition-probability-matrix-tpm">Transition Probability Matrix (TPM)</h3>
<p>In the simple addressed problem, the warehouse grid is of size the 2x2. Therefore, so have 2Â·2=4 possible actions and 1536 different states. In order to compute the probability actions, is necessary to iterate through all possible actions as well as all generated states. Then assign the possibility of having a colored item or being empty derived from the training data frequencies.
It should also be taken into account if the warehouse grid is already full and if the linked operation is invalid. In that case, the transition probabilities are kept 0. To assert that the computation was correct, it was checked that all he probabilities for a particular state sum 1.</p>
<h3 id="regard-matrix">Regard Matrix</h3>
<p>The aim of the reinforcement learning algorithm is to maximize the obtained rewards. In this problem, the distance should influence the reward. Thus, the simple criteria to assign the negative distances values from the origin warehouse cell (1,1). At the same time, not from every state the robot can transition to other state. For the entries in the reward matrix, as the movement action would be invalid, a penalization of -10000 was taken as a reward.
With the necessary TMP and R, a MDP model is trained within the python-MDPtoolbox package. It contains the most common Reinforcement Learning training approaches, such as Value Iteration and Policy Iteration. These were the best models selected for the simplified problem. The discount factor and maximum iteration hyperparameters were set to 0.9 and 750 respectively.</p>
<h2 id="evaluation">Evaluation</h2>
<p>MDP policy refers to a solution to which specifies an action for each state. Value iteration is defined as an algorithm that gives an optimal policy for a MDP, i.e., The ideal MDP solution. In the training run, for policy iteration 6 iterations were performed whereas for value iteration 35 were performed.
To evaluate the model, a test dataset containing 60 pair of movement actions and colored items was used. Although different MDP algorithms were tried, there was no change on the result. The movements distance need was 232 for both Value Iteration and Policy Iteration. That may be due to on the restricted problem, the simple algorithm is already learning the optimal policy for the given rewards.
In order to assess if the policy represents a better utility than random, a simple random walk approach through the grid was also implemented. In that the distance or movements performed by the robot are count. The random distance, although the random seed was fix, it rounds the range of 264.</p>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th style="text-align:center">Move Distance</th>
</tr>
</thead>
<tbody>
<tr>
<td>Value Iteration</td>
<td style="text-align:center">232</td>
</tr>
<tr>
<td>Policy Iteration</td>
<td style="text-align:center">232</td>
</tr>
<tr>
<td>Random Walk</td>
<td style="text-align:center">264</td>
</tr>
</tbody>
</table>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/reinforcement-learning/">Reinforcement Learning</a>
  
  <a class="badge badge-light" href="/tag/python/">Python</a>
  
  <a class="badge badge-light" href="/tag/eda/">EDA</a>
  
  <a class="badge badge-light" href="/tag/artificial-intelligence/">Artificial Intelligence</a>
  
  <a class="badge badge-light" href="/tag/open-source/">Open Source</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://mariamonzon.com/project/reinforcement-learning-warehouse/&amp;text=Warehouse%20storing%20route%20optimization%20with%20Reinforcement%20Learning" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://mariamonzon.com/project/reinforcement-learning-warehouse/&amp;t=Warehouse%20storing%20route%20optimization%20with%20Reinforcement%20Learning" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Warehouse%20storing%20route%20optimization%20with%20Reinforcement%20Learning&amp;body=https://mariamonzon.com/project/reinforcement-learning-warehouse/" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://mariamonzon.com/project/reinforcement-learning-warehouse/&amp;title=Warehouse%20storing%20route%20optimization%20with%20Reinforcement%20Learning" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Warehouse%20storing%20route%20optimization%20with%20Reinforcement%20Learning%20https://mariamonzon.com/project/reinforcement-learning-warehouse/" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://mariamonzon.com/project/reinforcement-learning-warehouse/&amp;title=Warehouse%20storing%20route%20optimization%20with%20Reinforcement%20Learning" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://mariamonzon.com/"><img class="avatar mr-3 avatar-circle" src="/authors/maria-monzon/avatar_hu51661e0f756b9d3138ea612a8422b121_3222171_270x270_fill_q75_lanczos_center.jpg" alt="Maria Monzon"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://mariamonzon.com/">Maria Monzon</a></h5>
      <h6 class="card-subtitle">Computer Vision and AI researcher</h6>
      <p class="card-text">My research interests include Computer Vision, Biomedical Image Analysis, Trustworhty Deep Learning and Machine Learning for healthcare.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/mariamonzon24/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/mariamonzon" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


















    <div class="project-related-pages content-widget-hr">
      
      

      
      
      

      
      
      

      
      
      
    </div>
  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  

  

  

  
  






  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    Â© 2022 Maria Monzon. This work is licensed under <!-- raw HTML omitted -->CC BY NC ND 4.0<!-- raw HTML omitted -->
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <!-- raw HTML omitted -->Wowchemy<!-- raw HTML omitted --> â€” the free, <!-- raw HTML omitted -->open source<!-- raw HTML omitted --> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.46271ef31da3f018e9cd1b59300aa265.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  







<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js" type="module"></script>








  
  


<script src="/en/js/wowchemy.min.a6238d5886fa4a2f7cf92df25709326f.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>
















</body>
</html>
